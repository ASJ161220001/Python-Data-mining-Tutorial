# Day11 : 文章关键词提取：TF-IDF

> **作者**：长行
>
> **时间**：2020.05.10

关键词提取是词语颗粒度的信息抽取的一种重要的需求，即提取文章中重要的词语。

关键词提取的常用方法包括词频统计、TF-IDF和TextRank等。

其中，词频和TextRank属于单文档算法，即只需一篇文章即可提取出其中的关键词；而TF-IDF则属于多文档宣发，需要其他文档的辅助来提取当前文章的关键词。

## TF-IDF原理

因为如果一个词在越多的文档里出现，则越说明这个词不能体现出文档的特色。

相较于词频统计的方法，TF-IDF（term frequency–inverse document frequency）在考虑文档中词语出现频率的同时，还考虑了词语相较于其他文档的稀有程度，即还有多少其他的文档包含这个词语。

TF-IDF的计算方法如下：

![img](E:\【有道云笔记】\weixinobU7VjnGIqORtayCj-b7o8rEdBNc\4040605da1f94cc6acb09f0703d54019\lip_image002.png)

其中t表示单词，d表示文档，TF(t,d)表示单词t在文档d中的出现频次，DF(t)表示包含单词t的文档数量，IDF表示DF的倒数。

> 例如，我们统计1000篇与古风相关的文章的关键词。已知其中有800篇文章都包含“古风”这个词，而只有50篇文章包含“七言律诗”这个词。在文章A中，出现了20次“古风”，10次“七言律诗”。
>
> 如果使用词频统计提取关键词，文章A中的关键词，“古风”的权重应为“七言律诗”的2倍；但是如果使用TF-IDF提取关键词，“古风”的权重应为25，而“七言律诗”的权重为200。可见，TF-IDF可以更有效地突出文章的个性。

## 基于HanLP实现的TF-IDF

我们参考HanLP在Github中的案例进行尝试：

```python
from pyhanlp import *

TfIdfCounter = JClass('com.hankcs.hanlp.mining.word.TfIdfCounter')

if __name__ == '__main__':
    counter = TfIdfCounter()
    counter.add("《女排夺冠》", "女排北京奥运会夺冠")  # 输入多篇文档
    counter.add("《羽毛球男单》", "北京奥运会的羽毛球男单决赛")
    counter.add("《女排》", "中国队女排夺北京奥运会金牌重返巅峰，观众欢呼女排女排女排！")
    counter.compute()  # 输入完毕
    for id in counter.documents():
        print(id + " : " + counter.getKeywordsOf(id, 3).toString())  # 根据每篇文档的TF-IDF提取关键词
```

运行结果

```
《女排》 : [女排=5.150728289807123, 重返=1.6931471805599454, 巅峰=1.6931471805599454]
《女排夺冠》 : [夺冠=1.6931471805599454, 女排=1.2876820724517808, 奥运会=1.0]
《羽毛球男单》 : [决赛=1.6931471805599454, 羽毛球=1.6931471805599454, 男单=1.6931471805599454]
```

根据结果可以看到，文档中有效避免了“奥运会”这个在各个句子中都频繁出现的词拥有过高的权重。

> 学习参考文献：《自然语言处理入门》(何晗)：9.2.2